\documentclass[10pt]{article}

\usepackage{amsthm}
\usepackage[toc,page]{appendix}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{pslatex,palatino,avant,graphicx,color}
\usepackage{colortbl}
\usepackage{fullpage}
\usepackage{mathtools}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{caption}
%\usepackage{subfigure}
\usepackage{subcaption}
\usepackage{bm}
\usepackage{wrapfig}
\usepackage{enumerate}
\usepackage{rotating}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{bbm}
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents

\newtheorem{lemma}{Lemma}
%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{0in}%
\addtolength{\evensidemargin}{0in}%
\addtolength{\textwidth}{0in}%
\addtolength{\textheight}{0in}%
\addtolength{\topmargin}{0in}%


\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

\newcommand{\indicator}[1]{\mathbbm{1}\left( #1 \right) }
\newcommand{\hb}{\hat{b}}
\newcommand{\ha}{\hat{a}}
\newcommand{\htheta}{\hat{\theta}}
\newcommand{\halpha}{\hat{\alpha}}
\newcommand{\hmu}{\hat{\mu}}
\newcommand{\hsigma}{\hat{\sigma}}
\newcommand{\hphi}{\hat{\phi}}
\newcommand{\htau}{\hat{\tau}}
\newcommand{\heta}{\hat{\eta}}
\newcommand{\E}[1]{\mbox{E}\left[#1\right]}
\newcommand{\Var}[1]{\mbox{Var}\left[#1\right]}
\newcommand{\Indicator}[1]{\mathbbm{1}_{ \left( #1 \right) } }
\newcommand{\dNormal}[3]{ N\left( #1 \left| #2, #3 \right. \right) }
\newcommand{\Beta}[2]{\mbox{Beta}\left( #1, #2 \right)}
\newcommand{\alphaphi}{\alpha_{\hphi}}
\newcommand{\betaphi}{\beta_{\hphi}}
\newcommand{\expo}[1]{ \exp\left\{ #1 \right\}}
\newcommand{\tauSquareDelta}{\htau^2
  \left(\frac{1-\expo{-2\htheta\Delta}}{2\htheta} \right)}
\newcommand{\mumu}{\mu_{\hmu}}
\newcommand{\sigmamu}{\sigma^2_{\hmu}}
\newcommand{\sigmamuexpr}{\log\left( \frac{\VarX}{\EX^2} + 1 \right)}
\newcommand{\mumuexpr}{\log(\EX) -  \log\left( \frac{\VarX}{\EX^2} + 1 \right) /2 }

\newcommand{\EX}{\mbox{E}\left[ X \right] }
\newcommand{\VarX}{\mbox{Var}\left[ X \right] }
\newcommand{\mueta}{\mu_{\heta} }
\newcommand{\sigmaeta}{\sigma^2_{\heta}}
\newcommand{\sigmaetaexpr}{ \log\left( \frac{\VarX}{\EX^2} + 1 \right) }
\newcommand{\muetaexpr}{ \log(\EX) -  \sigmaetaexpr /2 }

\newcommand{\mualpha}{\mu_{\halpha} }
\newcommand{\sigmaalpha}{\sigma^2_{\halpha}}
\newcommand{\sigmaalphaexpr}{ \log\left( \frac{\VarX}{\EX^2} + 1 \right) }
\newcommand{\mualphaexpr}{ \log(\EX) -  \sigmaalphaexpr /2 }

\newcommand{\mutauexpr}{ \frac{2}{T} \EX }
\newcommand{\sigmatauexpr}{ \frac{4}{T^2} \Var{X}}

\newcommand{\alphatau}{\alpha_{\htau^2}}
\newcommand{\betatau}{\beta_{\htau^2}}

\newcommand{\Gam}[2]{\mbox{Gamma}\left( #1, #2 \right) }
\newcommand{\InvGam}[2]{\mbox{Inv-Gamma}\left( #1, #2 \right) }

%%% END Article customizations

%%% The "real" document content comes below...

% \newbox{\LegendeA}
% \savebox{\LegendeA}{
%    (\begin{pspicture}(0,0)(0.6,0)
%    \psline[linewidth=0.04,linecolor=red](0,0.1)(0.6,0.1)
%    \end{pspicture})}
% \newbox{\LegendeB}
%    \savebox{\LegendeB}{
%    (\begin{pspicture}(0,0)(0.6,0)
%    \psline[linestyle=dashed,dash=1pt 2pt,linewidth=0.04,linecolor=blue](0,0.1)(0.6,0.1)
%    \end{pspicture})}

\title{A Range-Based Bivariate Stochastic Volatility Model}
\author{Georgi Dinolov, Abel Rodriguez, Hongyun Wang}
\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 

\begin{document}
\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}

\bigskip

\vspace{1cm}
\noindent

\spacingset{1.00} % 
\section{Introduction}

The estimation and prediction of price volatility from market data is
an important problem in econometrics and finance
\citep{abramov2007estimation}, as well as practical risk management
\citep{brandt2006dynamic}. The literature on the subject of volatility
estimation is vast. Model-based approaches for a single observable
asset begin with the ARCH and GARCH models of \cite{engle1982} and
\cite{bollerslev1986}, moving on to stochastic volatility models (see
\cite{shephard2005selected-readings}, for example).

Multivariate equivalents for each of these model classes exist (see
\cite{bauwens2006multivariate} and \cite{asai2006multivariate} for
reviews of multivariate GARCH and for multivariate stochastic
volatility, respectively). However, the majority of work on the
subject uses opening and closing prices as data. This approach
invariably disregards information traditionally contained in financial
timeseries: the observed high and low price of an asset over the
quoted periods. To our current knowledge, only \cite{rodriguez2012}
use the observed maximum and minimum of prices in a likelihood to
estimate volatility. They do so, however, in a univariate
setting.

Explicit model-based approaches in the multivariate setting which take
into account extrema over observational periods are completely lacking
in the literature, because deriving an efficient approximation of the
corresponding likelihood function has hereto been an open problem. In
this paper, we use a result addressing this problem and introduce a
\textit{bivariate} stochastic volatility model which takes into
account the highest and lowest observed prices of each asset as part
of a likelihood-based (Bayesian) estimation procedure.

\section{Model}
The model we will estimate is a bivaraite, 1-factor stochastic volatility
model with leverage:

\begin{align}
  \left( \begin{array}{c}
           x_t \\
           y_t
         \end{array} \right) &= \left( \begin{array}{c}
                                         x_{t-\Delta} \\
                                         y_{t-\Delta}
                                       \end{array} \right) +
  \left( \begin{array}{c}
           \mu_x\Delta \\
           \mu_y\Delta \end{array} \right) +
  \left( \begin{array}{cc}
           \sqrt{1-\rho_t^2}\sigma_{x,t} & \rho_t \sigma_{x,t} \\
           0 & \sigma_{y,t}
         \end{array} \right)
               \left( \begin{array}{c}
                        \epsilon_{x,t} \\
                        \epsilon_{y,t}
                      \end{array} \right), \label{eq:process-evolution}\\
  \inf_{[t-\Delta,t]} x_\tau &= a_{x,t}&  \sup_{[t-\Delta,t]} x_\tau &= b_{x,t} & \inf_{[t-\Delta,t]} y_\tau &= a_{y,t} 
                                                                     & \sup_{[t-\Delta,t]} y_\tau &= b_{y,t} \nonumber \\
  \log(\sigma_{x,t+\Delta}) &= \alpha_x + \theta_x(\log(\sigma_{x,t}) - \alpha_x) + \tau_x \eta_{x,t}, \\
  \log(\sigma_{y,t+\Delta}) &= \alpha_y + \theta_y(\log(\sigma_{y,t}) - \alpha_y) + \tau_y \eta_{y,t}, \\
  \mbox{logit}((\rho_{t+\Delta} + 1)/2) &= \alpha_\rho + \theta_\rho\left(\mbox{logit}((\rho_{t}+1)/2) - \alpha_\rho\right) + \tau_{\rho} \eta_{\rho,t}. \label{eq:correlation-evolution}
\end{align}
The marginal distribution for all of the innovation terms
$\epsilon_{x,t}, \epsilon_{y,t}, \eta_{x,t}, \eta_{y,t},
\eta_{\rho,t}$ is the standard Gaussian distribution. The
\textit{leverage} terms are defined as
$E\left[\epsilon_{x,t}\, \eta_{x,t}\right] = \rho_{x}$ and
$E\left[\epsilon_{x,t}\, \eta_{x,t}\right] = \rho_{y}$. It should be
noted here that we are explicitly allowing the correlation of the
process to change over time in a mean-reverting fashion. Finally, we
explicitly write down the realized extrema over the periods
$[t-\Delta,t]$ to be included as data into the likelihood for the
dynamical model. We estimate all parameters and dynamical factors in a
fully Bayes framework via the augmented particle filter of
\cite{liu2001combined} which we will describe below.

\subsection{Likelihood for the observables}
Each period $[t-\Delta,t]$ has six associated observables: opening
coordinate $(x_{t-\Delta},y_{t-\Delta})$, closing coordinate
$(x_{t},y_{t})$, and the observed extrema in each nominal direction
$(a_{x,t}, b_{x,t}), (a_{y,t},b_{y,t})$. Given the evolution model in
(\ref{eq:process-evolution}), disregarding the information contained in
the extrema yields the usual bivariate Gaussian density in terms of
the volatility parameters and the state of the process at time $t-\Delta$: 

\[
  p(x_t,y_t| x_{t-\Delta}, y_{t-\Delta}, \mu_x, \mu_y, \sigma_{x,t}, \sigma_{y,t}, \rho_t) =
\]
\[
  \frac{1}{2\pi\,\,\Delta\,\,
    \sigma_{x,t}\sigma_{y,t}\sqrt{1-\rho_t^2}} \exp\left\{
    -\frac{1}{2\,\Delta(1-\rho_t^2)} \left( \frac{(x_t -
        x_{t-\Delta})^2}{\sigma_{x,t}^2} - 2\rho_t
      \frac{(x_{t}-x_{t-\Delta})(y_t-y_{t-\Delta})}{\sigma_{x,t}\sigma_{y,t}}
      + \frac{(y_t - y_{t-\Delta})^2}{\sigma_{y,t}^2}\right) \right\}.
\]
Incorporating the extreme values over $[t-\Delta,t]$ is accomplished
by considering the Fokker-Planck Equation for the forward,
continuous-time evolution of the probability density function of
$(x_t, y_t)$ and including $(a_{x,t}, b_{x,t}), (a_{y,t},b_{y,t})$ as
boundary conditions where the density is zero. The previous work
describes the method by which the full likelihood function is
found. However, for the purposes of the particle filter used to
estimate the model in this work, we improve upon the computational
method by performing a set of normalizing transformations, allowing
for more flexibility in the parameters for the basis functions in the
Galerkin approximation, and extrapolating over certain low-probability
regions of the parameter space.

\subsection{Improved likelihood computational method for low probability data}

\section{Estimation Methodology}
Given the highly non-linear hierarchical model
(\ref{eq:process-evolution}) - (\ref{eq:correlation-evolution}) and
the non-Gaussian observational likelihood, we use a particle filter to
estimate the collection of time-dependent parameters which we abbreviate to
\[
  \sigma_t := (\sigma_{x,t}, \sigma_{y,t}, \rho_t),
\]
as well as all of the time-constant parameters governing the evolution
of the process
\[
  \phi := (\alpha_x, \alpha_y, \alpha_\rho, \theta_x, \theta_y, \theta_\rho,
  \tau_x, \tau_y, \tau_\rho, \rho_x, \rho_y).
\]
Particle filters use a discrete mixture to represent the posterior
distribution $p(\sigma_t, \phi | \mathcal{D}_t)$, where
$\mathcal{D}_t$ represents all of the observable information up to
time $t$:
\[
  \mathcal{D}_t = (x_0, y_0, a_{x,\Delta}, b_{x,\Delta}, a_{y,\Delta},
  b_{y,\Delta}, x_\Delta, y_\Delta, \ldots, x_{t-\Delta},
  y_{t-\Delta}, a_{x,t}, b_{x,t}, a_{y,t}, b_{y,t}, x_t, y_t)
\]
Given $p(\sigma_t, \phi | \mathcal{D}_t)$, additional information at
time $t+\Delta$ is incorporated by updating each particle via an
appropriately chosen (importance) sampling distribution and Bayes'
Theorem. In the case of the augmented particle filter, [CITE], which
treats the structural parameters $\phi$ as known and fixed,

\section{Calibration Study}

\section{Application}

\bibliographystyle{plainnat}
\bibliography{master-bibliography}

\end{document}